{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "import xlsxwriter as xw\n",
    "import pathlib\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_activities(df):\n",
    "# Helper function for process_annotations\n",
    "# Sorts cycles after splitting raw annotations file into Day 1 and Day 2 data\n",
    "#\n",
    "# Inputs:  df - dataframe to sort annotations\n",
    "#\n",
    "# Outputs: df - processed dataframe\n",
    "    \"\"\"complete = set(np.array(['Heart Rate Variability', 'MDS-UPDRS #1: Finger Tapping',\n",
    "           'MDS-UPDRS #2: Hand Movements', 'MDS-UPDRS #3: Pronation-Supination',\n",
    "           'MDS-UPDRS #4: Toe Tapping', 'MDS-UPDRS #5: Leg Agility',\n",
    "           'MDS-UPDRS #6: Arising from Chair', 'MDS-UPDRS #7: Gait',\n",
    "           'MDS-UPDRS #8: Postural Stability', 'MDS-UPDRS #9: Postural Hand Tremor',\n",
    "           'MDS-UPDRS #10: Kinetic Hand Tremor', 'MDS-UPDRS #11: Rest Tremor',\n",
    "           'Motor #1: Standing', 'Motor #2: Walking', 'Motor #3: Walking while Counting',\n",
    "           'Motor #4: Finger to Nose', 'Motor #5: Alternating Hand Movements',\n",
    "           'Motor #6: Sit to Stand', 'Motor #7: Drawing on Paper',\n",
    "           'Motor #8: Typing on a Computer', 'Motor #9: Nuts and Bolts',\n",
    "           'Motor #10: Drinking Water', 'Motor #11: Organizing Folder',\n",
    "           'Motor #12: Folding Towels', 'Motor #13: Sitting']).flatten())\"\"\"\n",
    "\n",
    "    sorter = set(df.EventType.unique().flatten())\n",
    "    sorterIndex = dict(zip(sorter, range(len(sorter))))\n",
    "    \n",
    "    \"\"\"if (complete ^ sorter):\n",
    "        print('Missing: ' + str(complete ^ sorter))\"\"\"\n",
    "        \n",
    "    df['EventType_Rank'] = df['EventType'].map(sorterIndex)\n",
    "    df['Cycle'] = df.groupby('EventType')['Start Timestamp (ms)'].rank(ascending=True).astype(int)\n",
    "    df[df['EventType'].str.contains('MDS-UPDRS')] = df[df['EventType'].str.contains('MDS-UPDRS')].replace(to_replace={'Cycle': {2: 3}})\n",
    "    df[df['EventType'].str.contains('Heart')] = df[df['EventType'].str.contains('Heart')].replace(to_replace={'Cycle': {1: 'NaN', 2: 'NaN'}})\n",
    "    df.sort_values(['EventType', 'EventType_Rank', 'Start Timestamp (ms)'], axis=0)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def process_annotations(path):\n",
    "# Splits raw annotation file into Day 1 and Day 2 data by sheet in the .xlsx file\n",
    "# 'RawAnnotations.xlsx'\n",
    "#\n",
    "# Inputs:  path - filepath of the subject folder containing annotations.csv\n",
    "#\n",
    "# Outputs: d1_df - dataframe containing all Day 1 activities and timestamps\n",
    "#          d2_df - dataframe containing all Day 2 activities and timestamps\n",
    "    df = pd.read_csv(os.path.join(path, 'annotations.csv'))\n",
    "    del df['Timestamp (ms)']\n",
    "    del df['AnnotationId']\n",
    "    del df['AuthorId']\n",
    "    \n",
    "    df['Start Timestamp (ms)'] = pd.to_datetime(df['Start Timestamp (ms)'], unit='ms', utc=True).dt.tz_localize('UTC').dt.tz_convert('US/Central')\n",
    "    df['Stop Timestamp (ms)'] = pd.to_datetime(df['Stop Timestamp (ms)'], unit='ms', utc=True).dt.tz_localize('UTC').dt.tz_convert('US/Central')\n",
    "            \n",
    "    testInfo = df[df.EventType == 'Testing Day'].dropna(how='any', axis=0)\n",
    "    del testInfo['Stop Timestamp (ms)']\n",
    "    del testInfo['EventType']\n",
    "    del df['Value']\n",
    "    \n",
    "    testInfo = testInfo.rename(columns = {'Value':'Day', 'Start Timestamp (ms)':'Date'}).reset_index(drop=True)\n",
    "    testInfo['Date'] = testInfo['Date'].dt.date\n",
    "    \n",
    "    df = df[(df.EventType != 'Testing Day')]\n",
    "\n",
    "    Day1 = testInfo.loc[testInfo['Day'] == 'DAY 1', 'Date']\n",
    "    Day2 = testInfo.loc[testInfo['Day'] == 'DAY 2', 'Date']\n",
    "\n",
    "    d1_df = process_activities(df[df['Start Timestamp (ms)'].dt.date.isin(Day1)].reset_index(drop=True)).set_index('EventType')\n",
    "    d2_df = process_activities(df[df['Start Timestamp (ms)'].dt.date.isin(Day2)].reset_index(drop=True)).set_index('EventType')\n",
    "    total_df = process_activities(df.reset_index(drop=True))\n",
    "    \n",
    "    file = os.path.join(path, 'RawAnnotations.xlsx')\n",
    "    writer = pd.ExcelWriter(file, options={'remove_timezone': True})\n",
    "    d1_df.to_excel(writer, sheet_name='Day 1')\n",
    "    d2_df.to_excel(writer, sheet_name='Day 2')\n",
    "    writer.save()\n",
    "    \n",
    "    return d1_df, d2_df, total_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-b1c46e4c20b8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     64\u001b[0m             \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilenames\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[0mlocation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelative_to\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\\\\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m             \u001b[0mtemp_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m             \u001b[0mtemp_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Timestamp (ms)'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Timestamp (ms)'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ms'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mutc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtz_localize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'UTC'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtz_convert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'US/Central'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[0mtemp_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtemp_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Timestamp (ms)'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\adai\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    653\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    654\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 655\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    656\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    657\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\adai\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    409\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    410\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 411\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    412\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    413\u001b[0m         \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\adai\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1003\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'skipfooter not supported for iteration'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1004\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1005\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1006\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1007\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'as_recarray'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\adai\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1746\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1747\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1748\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1749\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1750\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read (pandas\\_libs\\parsers.c:10862)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory (pandas\\_libs\\parsers.c:11138)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows (pandas\\_libs\\parsers.c:12175)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data (pandas\\_libs\\parsers.c:14136)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens (pandas\\_libs\\parsers.c:14858)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype (pandas\\_libs\\parsers.c:15629)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\adai\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\dtypes\\common.py\u001b[0m in \u001b[0;36mis_integer_dtype\u001b[1;34m(arr_or_dtype)\u001b[0m\n\u001b[0;32m    735\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    736\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 737\u001b[1;33m \u001b[1;32mdef\u001b[0m \u001b[0mis_integer_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr_or_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    738\u001b[0m     \"\"\"\n\u001b[0;32m    739\u001b[0m     \u001b[0mCheck\u001b[0m \u001b[0mwhether\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mprovided\u001b[0m \u001b[0marray\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mof\u001b[0m \u001b[0man\u001b[0m \u001b[0minteger\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"error = pd.read_excel(path_error, sheetname='Errors')\n",
    "error = error[error['Participant'] == 1004].set_index('Participant')\n",
    "\n",
    "if not error[error['Error'] == 'Split'].empty:\n",
    "    split = error[error['Error'] == 'Split']\n",
    "    print(split)\n",
    "    if (split.loc[split['Error'] == 'Split', 'Day'] == 'Day 1').bool:\n",
    "        print('Day 1')\n",
    "    else:\n",
    "        print('Day 2')\n",
    "elif not error[error['Error'] == 'Merge'].empty:\n",
    "    \n",
    "elif not error[error['Error'] == 'Absent'].empty:\n",
    "    \n",
    "else:\n",
    "\"\"\"\n",
    "\n",
    "complete = list(['Heart Rate Variability', 'MDS-UPDRS #1: Finger Tapping',\n",
    "           'MDS-UPDRS #2: Hand Movements', 'MDS-UPDRS #3: Pronation-Supination',\n",
    "           'MDS-UPDRS #4: Toe Tapping', 'MDS-UPDRS #5: Leg Agility',\n",
    "           'MDS-UPDRS #6: Arising from Chair', 'MDS-UPDRS #7: Gait',\n",
    "           'MDS-UPDRS #8: Postural Stability', 'MDS-UPDRS #9: Postural Hand Tremor',\n",
    "           'MDS-UPDRS #10: Kinetic Hand Tremor', 'MDS-UPDRS #11: Rest Tremor',\n",
    "           'Motor #1: Standing', 'Motor #2: Walking', 'Motor #3: Walking while Counting',\n",
    "           'Motor #4: Finger to Nose', 'Motor #5: Alternating Hand Movements',\n",
    "           'Motor #6: Sit to Stand', 'Motor #7: Drawing on Paper',\n",
    "           'Motor #8: Typing on a Computer', 'Motor #9: Nuts and Bolts',\n",
    "           'Motor #10: Drinking Water', 'Motor #11: Organizing Folder',\n",
    "           'Motor #12: Folding Towels', 'Motor #13: Sitting'])\n",
    "\n",
    "path = r'C:\\Users\\adai\\Documents\\PD Study Data\\RawData\\1004'\n",
    "\n",
    "day1_df, day2_df, total_df = process_annotations(path)\n",
    "\n",
    "accel_writer = pd.ExcelWriter(os.path.join(path, 'AccelData.xlsx'), options={'remove_timezone': True})\n",
    "gyro_writer = pd.ExcelWriter(os.path.join(path, 'GyroData.xlsx'), options={'remove_timezone': True})\n",
    "elec_writer = pd.ExcelWriter(os.path.join(path, 'ElecData.xlsx'), options={'remove_timezone': True})\n",
    "\n",
    "locations = [locs for locs in os.listdir(path) if os.path.isdir(os.path.join(path, locs))]\n",
    "\n",
    "accel = {locs: pd.DataFrame() for locs in locations}\n",
    "gyro = {locs: pd.DataFrame() for locs in locations}\n",
    "elec = {locs: pd.DataFrame() for locs in locations}\n",
    "\n",
    "for root, dirs, files in os.walk(path, topdown=True):\n",
    "    for filenames in files:\n",
    "        if filenames.endswith('accel.csv'):\n",
    "            p = pathlib.Path(os.path.join(root, filenames))\n",
    "            location = str(p.relative_to(path)).split(\"\\\\\")[0]\n",
    "            temp_df = pd.read_csv(p)\n",
    "            temp_df['Timestamp (ms)'] = pd.to_datetime(temp_df['Timestamp (ms)'], unit='ms', utc=True).dt.tz_localize('UTC').dt.tz_convert('US/Central')\n",
    "            temp_df = temp_df.set_index('Timestamp (ms)')\n",
    "            accel[location] = accel[location].append(temp_df)\n",
    "            \n",
    "        elif filenames.endswith('gyro.csv'):\n",
    "            p = pathlib.Path(os.path.join(root, filenames))\n",
    "            location = str(p.relative_to(path)).split(\"\\\\\")[0]\n",
    "            temp_df = pd.read_csv(p)\n",
    "            temp_df['Timestamp (ms)'] = pd.to_datetime(temp_df['Timestamp (ms)'], unit='ms', utc=True).dt.tz_localize('UTC').dt.tz_convert('US/Central')\n",
    "            temp_df = temp_df.set_index('Timestamp (ms)')\n",
    "            gyro[location] = gyro[location].append(temp_df)\n",
    "            \n",
    "        if filenames.endswith('elec.csv'):\n",
    "            p = pathlib.Path(os.path.join(root, filenames))\n",
    "            location = str(p.relative_to(path)).split(\"\\\\\")[0]\n",
    "            temp_df = pd.read_csv(p)\n",
    "            temp_df['Timestamp (ms)'] = pd.to_datetime(temp_df['Timestamp (ms)'], unit='ms', utc=True).dt.tz_localize('UTC').dt.tz_convert('US/Central')\n",
    "            temp_df = temp_df.set_index('Timestamp (ms)')\n",
    "            elec[location] = elec[location].append(temp_df)\n",
    "\n",
    "\n",
    "print(accel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_dict = {acts: pd.DataFrame() for acts in complete}\n",
    "\n",
    "for activities in complete:\n",
    "    loc_dict = {locs: pd.DataFrame() for locs in locations}\n",
    "    data = {'accel': pd.DataFrame(), 'gyro': pd.DataFrame(), 'elec': pd.DataFrame()}\n",
    "    \n",
    "    temp_df = total_df[total_df['EventType'] == activities].reset_index(drop=True).set_index('EventType')\n",
    "    print(temp_df)\n",
    "    \n",
    "    for sensors in locations:\n",
    "        if not accel[sensors].empty:\n",
    "            startTime = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def absent_timestamps(df, absent):\n",
    "# Inputs:  df - original annotation dataframe\n",
    "#          absent - dataframe of absent (missing or skipped) activity labels\n",
    "#\n",
    "# Outputs: df_new - updated dataframe with placeholder activities to indicate\n",
    "#                   the activity was missing\n",
    "    for labels in missing:\n",
    "\n",
    "\n",
    "\n",
    "def merge_timestamps(df, merge):\n",
    "# Inputs:  df - original annotation dataframe\n",
    "#          merge - dataframe of activities to merge\n",
    "#\n",
    "# Outputs: df_new - updated dataframe with merged timestampes per activities\n",
    "    for labels in merge:\n",
    "    \n",
    "\n",
    "    \n",
    "def split_timestamps(df, split):\n",
    "# Inputs:  df - original annotation dataframe\n",
    "#          split - dataframe of activity labels needed to be split\n",
    "#\n",
    "# Outputs: df_new - updated dataframe with split activities\n",
    "    for labels in split:\n",
    "        \n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
